{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2YldTARgGmH"
      },
      "source": [
        "##Lina Conti LI M2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADMDWc5LgpC0"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "# WSD by fine-tuning a transformer-based pre-trained model\n",
        "\n",
        "**Copy this notebook (File>Save a copy in Drive)**\n",
        "\n",
        "**Add your name in notebook's name and in notebook's body**\n",
        "\n",
        "**Deadlines**\n",
        "- share your copy with me before **January 3rd**\n",
        "- don't forget to give me **edit rights**\n",
        "- the execution traces should be visible\n",
        "- **Strong advice**: \n",
        "  - do the TODO1 and TODO2 by next lab session (Dec 16th)\n",
        "  - freeze the FlauBERT's parameters in your preliminary experiments\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUrBv8Gvg2bE"
      },
      "source": [
        "We will use the French FrameNet \"[ASFALDA](http://asfalda.linguist.univ-paris-diderot.fr/frameIndex.xml)\" dataset to experiment the Word Sense Disambiguation task (WSD).\n",
        "\n",
        "In this dataset, some words have been manually associated with a semantic frame:\n",
        "- these words are called the **\"targets\"**\n",
        "- find the correct frame for a given word token corresponds to a word sense disambiguation task (WSD)**\n",
        "- note though that a single frame pertains to several lexical units (e.g. FR_Commerce_buy => acheter.v, achat.n, acquérir.v, etc...)\n",
        "- for this lab session, sentences containing several targets have been duplicated: each line corresponds to a (sentence, target) pair.\n",
        "\n",
        "FrameNet data also contain annotations for the semantic roles of semantic arguments (Buyer, Seller, Goods ...), which will be ignored for this lab session.\n",
        "\n",
        "The objective is to build a classifier:\n",
        "- input = a sentence + target pair\n",
        "- output = a probability distribution over the various \"senses\" (namely frames)\n",
        "  - in basic version, we do not impose that a given target be associated with its possible senses only (namely those that were seen in the training data for this target lemma).\n",
        "\n",
        "A central trait of our classifier will be to use the contextual representation of the target, as output by a transformer-based pre-trained language model.\n",
        "\n",
        "Note that *BERT*-like models provide vectors for tokens, each token being potentially a subword.\n",
        "**In your base version, you will use the FlauBERT vector of the first token of the target word.**\n",
        "\n",
        "Example: for the target *comprenions* in:\n",
        "\n",
        "*Nous comprenions bien le cours*\n",
        "\n",
        "tokenized as :\n",
        "\n",
        "'\\<s>', 'Nous\\</w>', 'compren', 'ions\\</w>', 'bien\\</w>', 'le\\</w>', 'cours\\</w>', '.\\</w>, '\\</s>'\n",
        "\n",
        "you will use the last hidden vector of \"compren\".\n",
        "\n",
        "The base classifier will be a neural network comprising\n",
        "- the pre-trained language model\n",
        "- which provides the hidden vector of the 1st token of the target word\n",
        "- plus a simple linear layer + softmax into the set of frames seen in the training set.\n",
        "\n",
        "We have a single classifier for all lemmas. In basic version, no constraint on which frames can be associated with each target-lemma.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xp3IN9YQexxx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "#from tqdm import tqdm  \n",
        "from tqdm.notebook import tqdm # for progress bars in notebooks\n",
        "from random import shuffle\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_c3C5Pzexx-"
      },
      "source": [
        "## Naming conventions\n",
        "\n",
        "- sentences are already segmented into words (with a rule-based tokenizer)\n",
        "- but are not segmented into subwords yet\n",
        "- we use \"word\" or \"w\" for the tokens obtained after pre-segmentation\n",
        "- and \"token\" for units obtained after *BERT*-like tokenization (BPE ou WordPiece etc...)\n",
        "\n",
        "- in variable names, we distinguish \n",
        " - integer identifiers for symbols \n",
        "   (for the token vocabulary, the frame vocabulary ...)\n",
        " - versus the rank of a unit (either word or token) within a sequence\n",
        "- tid => token identifier\n",
        "- trk / wrk => token rank / rank of a word in a sequence\n",
        "- tg => \"target\", so \n",
        " - tg_wrk = rank of the target word\n",
        " - tg_trk = rank of the first token of the target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvqLZ8HGR-GT"
      },
      "source": [
        "## Enable use of a GPU\n",
        "\n",
        "(TODO only at the end, when actually testing / training on full batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1clXe8e2SBta",
        "outputId": "cb540469-e590-471f-b447-b4f17feb5bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use GPU 0 (Tesla T4) of compute capability 7.5 with 15.84Gb total memory.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# in order to use a GPU\n",
        "# modify notebook settings:\n",
        "# Edit > Notebook settings > Hardware accelerator => select \"GPU\"\n",
        "\n",
        "# if a GPU is available, we will use it\n",
        "if torch.cuda.is_available():\n",
        "    # objet torch.device          \n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "        \n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())    \n",
        "    device_id = torch.cuda.current_device()\n",
        "    gpu_properties = torch.cuda.get_device_properties(device_id)\n",
        "    print(\"We will use GPU %d (%s) of compute capability %d.%d with \"\n",
        "          \"%.2fGb total memory.\\n\" % \n",
        "          (device_id,\n",
        "          gpu_properties.name,\n",
        "          gpu_properties.major,\n",
        "          gpu_properties.minor,\n",
        "          gpu_properties.total_memory / 1e9))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfm0CXb9exyF"
      },
      "source": [
        "## \"ASFALDA\" dataset\n",
        "\n",
        "A French FrameNet, comprising about 16000 annotated targets, into about 100 distinct frames, along with their semantic role annotations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kySX0ye3jdpP"
      },
      "source": [
        "### Fetching the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRkusCSCjg8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f510b4ee-f5c6-43fd-f3d6-1614b9a2326a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=0cd37e265e745295cb55ec1574e762fe035f2a741179c41febc120cbfd831c77\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Downloading dataset\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists('./asfalda_data_for_wsd/'):\n",
        "  # shell commands can be run using !\n",
        "  !pip install wget\n",
        "  import wget\n",
        "  \n",
        "  # The URL for the dataset zip file.\n",
        "  url = 'http://www.linguist.univ-paris-diderot.fr/~mcandito/divers/asfalda_data_for_wsd.tgz'\n",
        "\n",
        "  \n",
        "  if not os.path.exists('./asfalda_data_for_wsd.tgz'):\n",
        "    print('Downloading dataset')\n",
        "    wget.download(url, './asfalda_data_for_wsd.tgz')\n",
        "    !tar zxf asfalda_data_for_wsd.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_2cjFvYfOn3"
      },
      "source": [
        "### Data loading method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYQhZaBzexyF"
      },
      "outputs": [],
      "source": [
        "def load_asfalda_data(gold_data_file, split_info_file):\n",
        "    \"\"\"\n",
        "        Inputs: - asfalda gold data file\n",
        "                - file indicating the corpus type for each sentence id\n",
        "\n",
        "        Returns 4 dictionaries (whose keys are corpus types (train/dev/test))\n",
        "        - sentences = list of sentences, each sent is a list of words\n",
        "        - list of rank of target word in each sentence\n",
        "        - list of target lemmas\n",
        "        - gold labels\n",
        "\n",
        "        Example:\n",
        "        sentences['train'] = [['Le', 'code', 'comprend', 'des', 'erreurs','.'],\n",
        "                              ['Comprends', '-tu', '?']]\n",
        "         # the targets are the 3rd and first words                     \n",
        "        tg_wrks['train'] = [2, 0]\n",
        "        tg_lemmas['train'] = ['comprendre', 'comprendre']\n",
        "        labels['train'] = ['frame1', 'frame2']\n",
        "                                \n",
        "    \"\"\"\n",
        "    # load the usual split into train / dev / test\n",
        "    s = open(split_info_file)\n",
        "    lines = [ l[:-1].split('\\t') for l in s.readlines() ]\n",
        "    split_info_dic = { line[0]:line[1] for line in lines }\n",
        "\n",
        "    # dev / train / test sentences\n",
        "    sentences = {'dev':[], 'train':[], 'test':[]}\n",
        "    # the word ranks (wrk) for the target words\n",
        "    tg_wrks = {'dev':[], 'train':[], 'test':[]}\n",
        "    # target lemmas\n",
        "    tg_lemmas = {'dev':[], 'train':[], 'test':[]}\n",
        "    # the labels of targets (= frames)\n",
        "    labels = {'dev':[], 'train':[], 'test':[]}\n",
        "\n",
        "    max_sent_len = {'dev':0, 'train':0, 'test':0}\n",
        "    max_tg_wrk = {'dev':0, 'train':0, 'test':0}\n",
        "\n",
        "    stream = open(gold_data_file)\n",
        "    for line in stream.readlines():\n",
        "        if line.startswith('#'):\n",
        "            continue\n",
        "        line = line.strip()\n",
        "        (sentid, tg_wrk, frame_name, tg_lemma, tg_pos, rest) = line.split('\\t',5)\n",
        "        # role annotation is ignored\n",
        "        # sentences are pre-segmented into space-separated words\n",
        "        # => we split, to use the is_split_into_words=True mode of the FlauBERT tokenizer\n",
        "        sentence = rest.split(\"\\t\")[-1].split(' ')\n",
        "        part = split_info_dic[sentid]\n",
        "        tg_wrk = int(tg_wrk)\n",
        "\n",
        "        l = len(sentence)\n",
        "        sentences[part].append(sentence)\n",
        "        labels[part].append(frame_name)\n",
        "        tg_wrks[part].append(tg_wrk)\n",
        "        tg_lemmas[part].append(tg_lemma)\n",
        "        if max_sent_len[part] < l: \n",
        "            max_sent_len[part] = l \n",
        "        if max_tg_wrk[part] < tg_wrk: \n",
        "            max_tg_wrk[part] = tg_wrk \n",
        "    print(\"Max sentence length:\", max_sent_len)\n",
        "    print(\"Max target rank (in words):\", max_tg_wrk)\n",
        "    \n",
        "    return sentences, tg_wrks, tg_lemmas, labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo-B32y4c308"
      },
      "source": [
        "### Data loading and defining ids for labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaKnFVJ0exyL",
        "outputId": "4d0d088e-b4ae-409e-f90e-299037d1866c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length: {'dev': 115, 'train': 271, 'test': 140}\n",
            "Max target rank (in words): {'dev': 96, 'train': 267, 'test': 115}\n",
            "dev : 2688 sentences, average lentgh=38.03\n",
            "train : 18657 sentences, average lentgh=38.99\n",
            "test : 3447 sentences, average lentgh=38.45\n"
          ]
        }
      ],
      "source": [
        "gold_data_file = './asfalda_data_for_wsd/sequoiaftb.asfalda_1_3.gold.uniq.nofullant.txt'\n",
        "\n",
        "# usual split train / dev / test for this corpus\n",
        "split_info_file = './asfalda_data_for_wsd/sequoiaftb_split_info'\n",
        "\n",
        "sentences, tg_wrks, tg_lemmas, label_strs = load_asfalda_data(gold_data_file,\n",
        "                                                              split_info_file)\n",
        "\n",
        "for p in sentences.keys():\n",
        "    avgl = sum([len(s) for s in sentences[p]])/len(sentences[p])\n",
        "    print(\"%s : %d sentences, average lentgh=%3.2f\" \n",
        "          %(p, len(sentences[p]), avgl))\n",
        "\n",
        "# creating label ids for frames seen in training set\n",
        "i2label = list(set(label_strs['train']))\n",
        "# id for unknown frame (for dev and test)\n",
        "i2label.append('*UNK*')\n",
        "\n",
        "label2i = {x:i for i,x in enumerate(i2label)}\n",
        "# id of special frame \"Other_sense\"\n",
        "i_OTHER_SENSE = label2i['Other_sense']\n",
        "\n",
        "# sequence of gold labels \n",
        "# for each sub-corpus (key = dev/train/test)\n",
        "labels = {}\n",
        "for p in label_strs.keys():\n",
        "    labels[p] = [label2i[x] if x in label2i else label2i['*UNK*'] for x in label_strs[p]]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Rgiftb-CQ5"
      },
      "source": [
        "### TODO1 : MFS Baseline (\"most frequent sense\")\n",
        "\n",
        "- Compute the most frequent sense of each **target-lemma**\n",
        "  (using frequencies in train)\n",
        "\n",
        "- and compute the MFS baseline, namely the accuracy obtained when choosing the most frequent sense of each target\n",
        "  - MFS in train\n",
        "  - MFS in dev (always using frequencies in train to get the most frequent senses)\n",
        "    - **NB**: in case of unknown target lemma, fall back on the most frequent frame in full training data\n",
        "\n",
        "- Study the items that are unknown in train:\n",
        "  - unknown target lemmas\n",
        "  - unknown frame / target-lemma associations\n",
        "  - unknown frames\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "d2f7R9YD9_OH",
        "outputId": "c202f427-c6fe-4abf-a4d1-daa6b23bebb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                lemmas                              labels  count\n",
              "0              aborder                   FR_Speak_on_topic     11\n",
              "2              aboutir                           Causation     24\n",
              "5        aboutissement                         Other_sense      4\n",
              "6            accentuer  FR_Contingency-Objective_influence      7\n",
              "8          acceptation                     FR_Taking_sides      4\n",
              "...                ...                                 ...    ...\n",
              "1477            éviter                          Preventing     49\n",
              "1478         évocation                   FR_Speak_on_topic      1\n",
              "1481           évoquer                   FR_Speak_on_topic     45\n",
              "1482    être_ce_à_dire                         Other_sense      2\n",
              "1483  être_fonction_de  FR_Contingency-Objective_influence      1\n",
              "\n",
              "[950 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07d6a938-db8e-47a3-a9e7-4d7b4082480c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemmas</th>\n",
              "      <th>labels</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aborder</td>\n",
              "      <td>FR_Speak_on_topic</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aboutir</td>\n",
              "      <td>Causation</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>aboutissement</td>\n",
              "      <td>Other_sense</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>accentuer</td>\n",
              "      <td>FR_Contingency-Objective_influence</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>acceptation</td>\n",
              "      <td>FR_Taking_sides</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1477</th>\n",
              "      <td>éviter</td>\n",
              "      <td>Preventing</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1478</th>\n",
              "      <td>évocation</td>\n",
              "      <td>FR_Speak_on_topic</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1481</th>\n",
              "      <td>évoquer</td>\n",
              "      <td>FR_Speak_on_topic</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1482</th>\n",
              "      <td>être_ce_à_dire</td>\n",
              "      <td>Other_sense</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1483</th>\n",
              "      <td>être_fonction_de</td>\n",
              "      <td>FR_Contingency-Objective_influence</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>950 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07d6a938-db8e-47a3-a9e7-4d7b4082480c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07d6a938-db8e-47a3-a9e7-4d7b4082480c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07d6a938-db8e-47a3-a9e7-4d7b4082480c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Compute the most frequent sense of each target-lemma (using frequencies in train)\n",
        "import pandas as pd\n",
        "\n",
        "# Sends data to DataFrames\n",
        "train_df = pd.DataFrame({'lemmas': tg_lemmas['train'], 'labels': label_strs['train']})\n",
        "dev_df = pd.DataFrame({'lemmas': tg_lemmas['dev'], 'labels': label_strs['dev']})\n",
        "test_df = pd.DataFrame({'lemmas': tg_lemmas['test'], 'labels': label_strs['test']})\n",
        "\n",
        "# Counts how many times each lemma is associated with each of its labels\n",
        "MFS_df = train_df.groupby([\"lemmas\", \"labels\"]).size().to_frame(name = 'count').reset_index()\n",
        "# Selects only the label with the highest count for each lemma\n",
        "idx = MFS_df.groupby([\"lemmas\"])['count'].transform(max) == MFS_df['count']\n",
        "\n",
        "MFS_df = MFS_df[idx]\n",
        "MFS_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY1N2dUibPh0",
        "outputId": "aa378536-5c67-4c8f-ec2a-af3286e5181b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Other_sense\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Finds the most frequent sense in full training data\n",
        "default_sense = train_df['labels'].value_counts().idxmax()\n",
        "print(default_sense)\n",
        "\n",
        "# Fall back on it for unknown lemmas\n",
        "MFS = defaultdict(lambda: default_sense, zip(MFS_df.lemmas, MFS_df.labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slMbJe01WUdJ",
        "outputId": "4de65f69-2a42-4d9e-bdfa-454df0e93d2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8139572278501367"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# MFS baseline on train\n",
        "\n",
        "# Adds a column with the MFS prediction for each example\n",
        "train_df['MFS'] = train_df['lemmas'].apply(lambda lemma: MFS[lemma])\n",
        "\n",
        "# Computes accuracy\n",
        "(train_df.labels == train_df.MFS).sum() / train_df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgb1AzfuaKQQ",
        "outputId": "3bed189d-7c1a-4d23-b326-99149fb7b5a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7875744047619048"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# MFS baseline on dev\n",
        "\n",
        "# Adds a column with the MFS prediction for each example\n",
        "dev_df['MFS'] = dev_df['lemmas'].apply(lambda lemma: MFS[lemma])\n",
        "\n",
        "# Computes accuracy\n",
        "(dev_df.labels == dev_df.MFS).sum() / dev_df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF-HN4IVdQjr",
        "outputId": "9ae3250b-6cc1-4350-e9f3-644909455f0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7919930374238469"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# MFS baseline on test\n",
        "\n",
        "# Adds a column with the MFS prediction for each example\n",
        "test_df['MFS'] = test_df['lemmas'].apply(lambda lemma: MFS[lemma])\n",
        "\n",
        "# Computes accuracy\n",
        "(test_df.labels == test_df.MFS).sum() / test_df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtVS9_b6c9sc",
        "outputId": "4db520c4-16c0-4065-908e-07d362d600de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Study the items that are unknown in train\n",
        "\n",
        "# number of unknown target lemmas in dev\n",
        "dev_df[~dev_df.lemmas.isin(train_df.lemmas)].size # to see the lemmas comment out .size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2Ak-XcfgHYJ",
        "outputId": "0972db03-83ef-4117-8e57-79cf2b264868"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# unknown frames in dev (there are none!)\n",
        "dev_df[~dev_df.labels.isin(train_df.labels)].size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_bsNRcUgE8p",
        "outputId": "d02d12e4-0cba-4cfd-9980-bfe4b27044db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# number of unknown frame / target-lemma associations\n",
        "\n",
        "# frame / target-lemma associations in dev\n",
        "dev_associations = pd.Series( [ str(i) + str(j) for i,j in dev_df[['lemmas', 'labels']].values ] )\n",
        "\n",
        "# frame / target-lemma associations in train\n",
        "train_associations = [ str(i) + str(j) for i,j in train_df[['lemmas', 'labels']].values ]\n",
        "\n",
        "# filters by if the associations in dev are present in train\n",
        "dev_df[~dev_associations.isin(train_associations)].size # to see the lemmas comment out .size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE28jS8Jgqrz"
      },
      "source": [
        "## Data encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPbOlFK9nLoU"
      },
      "source": [
        "### FlauBERT tokenization\n",
        "\n",
        "We use the FlauBERT model, using the Huggingface \"transformers\" module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4DfehySexyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96facbf8-ec7d-44d8-f06d-11abbcc32233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacremoses) (2022.6.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sacremoses) (4.64.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=465fbf81b4133ce2dbbc2a2e018958c40d31c32a382b9dd5a9c42f2d9c31fead\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import transformers\n",
        "except ImportError:\n",
        "  !pip install transformers\n",
        "  \n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "\n",
        "# flaubert's tokenization uses as first step a tokenization into words by moses\n",
        "try:\n",
        "  import sacremoses\n",
        "except ImportError:\n",
        "  !pip install sacremoses\n",
        "  import sacremoses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJiKhfxhexyV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "5e7465a736804aa09fd27f8757a6f479",
            "1187eac5919c4ed6bc71e8cf188d48e5",
            "898340f77607446abe6df27e33490c72",
            "3e80a4a990de4bbdb72d7c240f056bd1",
            "415b0d74ac1a43b1b078319813975505",
            "ccaf0691ccb94516b383693177222cde",
            "7f455f64075749369398772db9115446",
            "6204413c55884a65aeb0be525a8c3ff9",
            "2cacbeb290ca4afa84d56e9dcd52d329",
            "c8cf651b69e54d2fb898f2e4836affae",
            "7a85ac5a5d8b48e3846b9c2d872276a6",
            "bcbf1eb91e1a41a18d56a6aa2e9f2ae8",
            "a8b97bc5d55e45b7994dfdc0e8930f40",
            "cc685603f54b44b586bd66cecfe1bbd4",
            "6d34d1adc92f4216a604ac2055565231",
            "8f2f6524e96a447b9c935f8efd14787d",
            "5c83e8ffcde04a18ae9b7c482c199664",
            "83ddeba84ec34445ba3c6ba6be426f93",
            "8b98f099d8884134889de26a2cb7b75e",
            "6684c23529184193aa737636621e1037",
            "f47514275b744841b4db1300af057a35",
            "b12afaafc9e54c699c9c755af10e0d0e",
            "f235ac96cf38423da305c6171db88c64",
            "c25691722bb6401f9917887fe54fa198",
            "57abc02fb02045a1820a6824209d6184",
            "fa8e5c31de3849cfaac0807921fbb27f",
            "9c10991d921f42608e8320ef89440b63",
            "d3cdefbf686e4ca1a031280ed4135a24",
            "738857fe0b404704b217013138604933",
            "449d706b28a743e6b3daa82c5aa8744e",
            "e4750320a4c244a9b3667563d40e45aa",
            "f967f713f7f4471489205c74ea370f5a",
            "37a904a758014211a2a6962ea0f8edf8",
            "83afd2924f8c48a794d072864615a432",
            "5c7497af351f4f14989dabc38da34d5c",
            "df6f571ef05b4581a54a45ef0fa3e2c2",
            "f39313e28cf74e898dbeb575a691f01a",
            "752e47be8999489094eb11e8c704a87b",
            "c4491356ec2b49bd8748ce8d7713e337",
            "8088ba76a156495fb2506fa06ea6b087",
            "8301e35efd58444d9e8d82f8412713b2",
            "88d1bbbd69214de5b359c035fdf603b4",
            "9ed363b6d28948919a89fcc2eb6cde22",
            "6b40ca9e0c994101a1d04e91cacee63c"
          ]
        },
        "outputId": "f189fcdf-c045-4244-a442-66bff9f74aaa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e7465a736804aa09fd27f8757a6f479"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.50k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcbf1eb91e1a41a18d56a6aa2e9f2ae8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.56M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f235ac96cf38423da305c6171db88c64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/896k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83afd2924f8c48a794d072864615a432"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# We choose the FlauBERT model\n",
        "\n",
        "# we load tokenizer and config for now\n",
        "flaubert_tokenizer = AutoTokenizer.from_pretrained(\"flaubert/flaubert_base_cased\")\n",
        "flaubert_config = AutoConfig.from_pretrained(\"flaubert/flaubert_base_cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMmtutNBexyQ"
      },
      "source": [
        "### TODO2: Encoding method\n",
        "\n",
        "The objective is to apply FlauBERT's tokenization, **keeping track of the position of the tokens of the targets**.\n",
        "\n",
        "Follow the instructions below to fill in the encode method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uqvpr6ovexya"
      },
      "outputs": [],
      "source": [
        "\n",
        "class WSDEncoder:\n",
        "    def __init__(self, tokenizer, config):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.config = config # to get indices of special tokens\n",
        "\n",
        "\n",
        "    def _tokenize_and_trk(self, sentences, tg_wrks):\n",
        "      '''\n",
        "      Input: \n",
        "          - sentences: list of sentences split into words\n",
        "          - tg_wrks: list of the ranks of target words\n",
        "\n",
        "      Returns:\n",
        "          - tid_seqs without padding / truncation nor special tokens,\n",
        "          - first_trk_of_targets: for each sentence, \n",
        "                                  the rank in corresponding tid_seq\n",
        "                                  of the first token of the target word\n",
        "      '''\n",
        "      first_trk_of_targets = [-1] * len(sentences)  # list of size len(sentences)\n",
        "      tid_seqs = [[] for _ in range(len(sentences))] # list of len(sentences) empty lists\n",
        "\n",
        "      for sent_id, sentence in enumerate(sentences):\n",
        "        nb_tokens = 0\n",
        "\n",
        "        for word_id, word in enumerate(sentence):\n",
        "\n",
        "            # Tokenize the word and add it to the tokenized sentence\n",
        "            new_tokens = self.tokenizer.encode(word, add_special_tokens=False)\n",
        "            tid_seqs[sent_id].extend(new_tokens)\n",
        "\n",
        "            # Look for the token rank of the target\n",
        "            if first_trk_of_targets[sent_id] == -1: # if we have not found the trk of the target for this sentence yet\n",
        "              if word_id == tg_wrks[sent_id]: # if we have found it now\n",
        "                first_trk_of_targets[sent_id] = nb_tokens\n",
        "              else:\n",
        "                nb_tokens += len(new_tokens)\n",
        "      \n",
        "      return tid_seqs, first_trk_of_targets\n",
        "\n",
        "\n",
        "    def _truncate(self, tid_seqs, first_trk_of_targets, max_length):\n",
        "      '''\n",
        "      Updates tid_seqs and first_trk_of_targets so the sentences are truncated\n",
        "      so as not to exceed max_length. Ensures that the target token does not get truncated.\n",
        "      '''\n",
        "      truncated_tid_seq = []\n",
        "      truncated_first_trk_of_targets = []\n",
        "\n",
        "      for seq_id, tid_seq in enumerate(tid_seqs):\n",
        "        # just truncate evirything to the right after max_length if that doesn't remove the target\n",
        "        if first_trk_of_targets[seq_id] < max_length:\n",
        "          truncated_tid_seq.append(tid_seq[:max_length])\n",
        "          truncated_first_trk_of_targets.append(first_trk_of_targets[seq_id])\n",
        "        # if the target was going to be truncated, slide the window that will be kept max_length tokens to the right\n",
        "        # (the target token will become the last token in the truncated sequence)\n",
        "        else:\n",
        "          truncated_tid_seq.append(tid_seq[first_trk_of_targets[seq_id]+1-max_length : first_trk_of_targets[seq_id]+1])\n",
        "          truncated_first_trk_of_targets.append(max_length-1)\n",
        "\n",
        "      return truncated_tid_seq, truncated_first_trk_of_targets\n",
        "\n",
        "\n",
        "    def _pad(self, tid_seqs, max_length):\n",
        "      '''\n",
        "      Updates tid_seqs so the sentences are padded to all be of length max_length.\n",
        "      '''\n",
        "      padded_tid_seq = []\n",
        "\n",
        "      for tid_seq in tid_seqs:\n",
        "        padding_size = max_length - len(tid_seq)  # nb of padding tokens to add (can be 0)\n",
        "        padded_tid_seq.append(tid_seq + padding_size * [self.config.pad_token_id])\n",
        "\n",
        "      return padded_tid_seq  \n",
        "\n",
        "\n",
        "    def _add_special_tokens(self, tid_seqs, first_trk_of_targets):\n",
        "      '''\n",
        "      Adds the bos and eos special tokens to tid_seqs and updates first_trk_of_targets accordingly.\n",
        "      '''\n",
        "      new_tid_seq = []\n",
        "      new_first_trk_of_targets = []\n",
        "\n",
        "      for seq_id, tid_seq in enumerate(tid_seqs):\n",
        "        new_tid_seq.append([self.config.bos_index] + tid_seq + [self.config.eos_index])\n",
        "        # the trk of targets has changed because we added the bos token before it\n",
        "        new_first_trk_of_targets.append(first_trk_of_targets[seq_id] + 1)\n",
        "\n",
        "      return new_tid_seq, new_first_trk_of_targets\n",
        "\n",
        "    \n",
        "    def encode(self, sentences, tg_wrks, max_length=100, verbose=False, is_split_into_words=True):\n",
        "      \"\"\" \n",
        "      Input: \n",
        "        - sentences : list of sentences\n",
        "           -- if is_split_into_words:\n",
        "              sentences are already split into words \n",
        "              (hence sentences = list of word strings [[w1, w2, w3], [w1, w2]...])\n",
        "           -- otherwise, sentences are to split on spaces to get words\n",
        "\n",
        "        - tg_wrks : list of the ranks of target words\n",
        "          (one rank per sentence, starting at 0 in a sentence)\n",
        "        - max_length : maximum length in number of tokens\n",
        "\n",
        "      Returns:\n",
        "        - tid_seqs : the sentences padded/truncated so that each contains max_length token ids\n",
        "        - first_trk_of_targets : for each sentence, \n",
        "                                 the rank in corresponding tid_seq\n",
        "                                 of the first token of the target word\n",
        "\n",
        "      Example with is_split_into_words=True: a batch with one sent\n",
        "      sentences = [ ['Conséquemment', ',', 'nous', 'comprendrions', '.'] ]\n",
        "      tg_wrks = [3]\n",
        "\n",
        "      if the sentence is tokenized into \n",
        "        '<s>', 'Con', 'séqu', 'emment</w>', ',</w>', 'nous</w>', 'compr', 'end', 'rions</w>', '.</w>' ....\n",
        "      the first token rank of the target \"comprendrions\" is 6 ('compr')\n",
        "\n",
        "      \"\"\"\n",
        "      if not is_split_into_words:\n",
        "        # Turns list into list of lists\n",
        "        sentences = [sent.split(' ') for sent in sentences]\n",
        "\n",
        "      # 1. apply flaubert tokenization *word per word*, and build\n",
        "      #    tid_seqs first without padding / truncation nor special tokens,\n",
        "      #    and keep track of token rank of first token of target word\n",
        "      tid_seqs, first_trk_of_targets = self._tokenize_and_trk(sentences, tg_wrks)\n",
        "\n",
        "      # 2. then truncate and pad, and add special symbols\n",
        "      # (write several methods for easier reading)\n",
        "      tid_seqs, first_trk_of_targets = self._truncate(tid_seqs, first_trk_of_targets, max_length-2)\n",
        "      tid_seqs, first_trk_of_targets = self._add_special_tokens(tid_seqs, first_trk_of_targets)\n",
        "      tid_seqs = self._pad(tid_seqs, max_length)\n",
        "      \n",
        "      return tid_seqs, first_trk_of_targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ySTnpTLexyi"
      },
      "source": [
        "#### Encoding test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fK8CV5Bexyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e161860-f459-4c54-9640-170cf75ac099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Len = 10 target token rank = 6 tid_seq = [0, 1198, 17358, 13299, 14, 65, 18719, 1999, 19614, 1]\n",
            "<s> Con séqu emment , nous compr end rions </s> \n",
            "\n",
            "Len = 10 target token rank = 3 tid_seq = [0, 55, 1138, 976, 23, 3842, 16, 1, 2, 2]\n",
            "<s> Le code comprend des erreurs . </s> <pad> <pad> \n",
            "\n",
            "Len = 10 target token rank = 4 tid_seq = [0, 158, 5213, 15, 965, 22, 14659, 896, 16, 1]\n",
            "<s> J' essaie de comprendre les transform ers . </s> \n",
            "\n",
            "Len = 10 target token rank = 6 tid_seq = [0, 59, 51, 34, 42, 83, 681, 20, 1138, 1]\n",
            "<s> Il n' a pas bien compris le code </s> \n",
            "\n"
          ]
        }
      ],
      "source": [
        "encoder = WSDEncoder(flaubert_tokenizer, flaubert_config)\n",
        "\n",
        "# test encoder\n",
        "test_sents = [\"Conséquemment , nous comprendrions .\",\n",
        "              \"Le code comprend des erreurs .\",\n",
        "            \"J' essaie de comprendre les transformers .\",  \n",
        "            \"Il n' a pas bien compris le code !\"]\n",
        "# target words are the occurrences of \"comprendre\"\n",
        "test_tg_wrks = [3, 2, 3, 5]\n",
        "max_length=10\n",
        "\n",
        "# uncomment to test your encode method\n",
        "tid_seqs, first_trk_of_targets = encoder.encode(test_sents, test_tg_wrks, max_length=10, verbose=True, is_split_into_words=False)\n",
        "\n",
        "for tid_seq, ft in zip(tid_seqs, first_trk_of_targets):\n",
        "    print(\"Len = %d target token rank = %d tid_seq = %s\" % (len(tid_seq), ft, str(tid_seq)))\n",
        "    print(' '.join([flaubert_tokenizer.decode(tid) for tid in tid_seq]), '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHApJ8mgexyn"
      },
      "source": [
        "### TODO3: WSDData class: full encoding and batch production"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMxpzaBhexyo",
        "outputId": "802fe6ad-6428-4999-fe6b-9cf6b945e1de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding part dev ...\n",
            "Encoding part train ...\n",
            "Encoding part test ...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class WSDData:\n",
        "    def __init__(self, corpus_type, sentences, tg_wrks, tg_lemmas, labels, encoder, max_length=100):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - corpus type string (train/dev/test)\n",
        "        - list of sentences (each sentence = list of word strings)\n",
        "        - list of target word ranks : one per sentence\n",
        "        - list of gold label id\n",
        "        - encoder = instance of WSDEncoder\n",
        "\n",
        "        - max_length = size of encoded sequences, in nb of bert tokens \n",
        "                      (padded / truncated via encoder.encode)\n",
        "    \n",
        "        Encodes all the data using the relevant identifiers\n",
        "        \"\"\"\n",
        "        \n",
        "        self.corpus_type = corpus_type # train / dev / test / val\n",
        "        self.size = len(sentences)\n",
        "        self.encoder = encoder\n",
        "\n",
        "        self.labels = labels       # gold label ids\n",
        "        self.sentences = sentences # list of list of word strings\n",
        "        self.tg_lemmas = tg_lemmas\n",
        "        \n",
        "        tid_seqs, tg_trks = encoder.encode(sentences, tg_wrks, max_length)\n",
        "\n",
        "        self.tid_seqs = tid_seqs  # sequences of token ids\n",
        "        self.tg_trks = tg_trks    # target token ranks\n",
        "        \n",
        "\n",
        "    def shuffle(self):\n",
        "      \"\"\"\n",
        "      Rearranges all the data in a new random order\n",
        "      (sentences, tg_lemmas, tg_trks, tid_seqs, labels)\n",
        "\n",
        "      NB: ** original order is lost **\n",
        "      \"\"\"\n",
        "      # Shuffles the five lists with same order\n",
        "      temp = list(zip(self.sentences, self.tg_lemmas, self.tg_trks, self.tid_seqs, self.labels))\n",
        "      shuffle(temp)\n",
        "      self.sentences, self.tg_lemmas, self.tg_trks, self.tid_seqs, self.labels = zip(*temp)\n",
        "\n",
        "      # The lists come out as tuples, and so must be converted to lists.\n",
        "      self.sentences, self.tg_lemmas =  list(self.sentences), list(self.tg_lemmas)\n",
        "      self.tg_trks, self.tid_seqs, self.labels = list(self.tg_trks), list(self.tid_seqs), list(self.labels)\n",
        "\n",
        "\n",
        "    # production of a batch\n",
        "    def make_batches(self, batch_size, device, shuffle_data=False):\n",
        "        \"\"\"\n",
        "        Returns an iterator over 4 torch tensors \n",
        "        - batch of token id sequences\n",
        "        - corresponding batch of target token ranks\n",
        "        - corresponding batch of labels for these targets\n",
        "        - corresponding batch of target lemmas\n",
        "        \"\"\"\n",
        "        if shuffle_data:\n",
        "            self.shuffle()\n",
        "\n",
        "        #batch generation\n",
        "        bstart = 0  # index where the batch starts\n",
        "        N = len(self.sentences)\n",
        "        while bstart < N:\n",
        "            bend = min(bstart+batch_size, N)  # index where the batch ends\n",
        "            # the torch tensors can be directly sent to the right device using .to(device)\n",
        "            b_tid_seqs = torch.LongTensor(self.tid_seqs[bstart:bend]).to(device)\n",
        "            b_tg_trks = torch.LongTensor(self.tg_trks[bstart:bend]).to(device)\n",
        "            b_labels = torch.LongTensor(self.labels[bstart:bend]).to(device)\n",
        "            b_tg_lemmas = self.tg_lemmas[bstart:bend]\n",
        "\n",
        "            # use \"yield\" function to return iterator\n",
        "            yield (b_tid_seqs, b_tg_trks, b_labels, b_tg_lemmas)\n",
        "            bstart += batch_size\n",
        "        \n",
        "\n",
        "MAX_LENGTH = 100\n",
        "wsd_data = {}\n",
        "# key = part of the split corpus (train/test/dev)\n",
        "for p in sentences.keys():\n",
        "    print(\"Encoding part %s ...\" % p)\n",
        "    wsd_data[p] = WSDData(p, sentences[p], tg_wrks[p], tg_lemmas[p], labels[p], \n",
        "                          encoder, max_length=MAX_LENGTH)\n",
        "    # we check that encoding provides the right lengths\n",
        "    for i, s in enumerate(wsd_data[p].tid_seqs):\n",
        "        if len(s) != MAX_LENGTH:\n",
        "            print(\"Size bug:\", i, s)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIw1BE1wexys"
      },
      "source": [
        "## WSDClassifier class: the network for WSD\n",
        "\n",
        "Base architecture = \n",
        "- the FlauBERT model\n",
        "- plus linear layer + softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3_mEfGUe3yH"
      },
      "source": [
        "### TODO4: Digression: matrix operation\n",
        "\n",
        "Matrix operation to fetch the bert hidden vector of the first\n",
        "token of the targets.\n",
        "\n",
        "Input is\n",
        "1. x = a tensor for a batch of (truncated/padded) sentences\n",
        "   containing the bert vectors for all tokens of each sentence\n",
        " \n",
        "2. r = a tensor for the token ranks of the first token of the targets\n",
        "  \n",
        "=> we want to keep only the bert vectors of these first tokens\n",
        "\n",
        "TODO: write down the shapes of tensors x and r and of the output tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0DWembWfXtA",
        "outputId": "ea169c2f-dfa9-4e02-e09e-010f3ac87696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5,  6,  7,  8],\n",
              "        [21, 22, 23, 24]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "x = torch.tensor([[[1, 2, 3, 4],\n",
        "                   [5, 6, 7, 8],\n",
        "                   [9, 10, 11, 12]],\n",
        "                  [[13, 14, 15, 16],\n",
        "                   [17, 18, 19, 20],\n",
        "                   [21, 22, 23, 24]]])  # shape batch_size x seq_length x emb_size\n",
        "print(x.shape)\n",
        "# if token ranks for the two sentences of the batch are (1,2) \n",
        "r = torch.tensor([1, 2])  # shape batch_length\n",
        "# => we want to get the [5, 6, 7, 8] and [21, 22, 23, 24] vectors\n",
        "\n",
        "# write down the matrix operation\n",
        "# see this source : https://discuss.pytorch.org/t/how-to-select-specific-vector-in-3d-tensor-beautifully/37724\n",
        "\n",
        "o = x[torch.arange(x.size(0)), r]\n",
        "o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ-w08okgaXv"
      },
      "source": [
        "### TODO5: The network : architecture, forward propagation, evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-Vpgmjmkn88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "c4262e64b4484577b3e5d67fb2c6a101",
            "1720abdea6f742d990958da02b3a2c9e",
            "316fc044b78d40b3b7a77f74525d2495",
            "a94e6bb12dec4ce8a67260a8f43268c6",
            "8d00811bf2d043d0ab5dee18601982e2",
            "fe70c3ad2dcc4dec8af9b239b67ea0bb",
            "f782810f814747679e7817eb8d0662b8",
            "253b4b474f6047fea2d60c902cb9c937",
            "06f8a9fc99714cf2b3fb644860b4ad8f",
            "7ccdac42fac046518c29c0a2ce7dfd57",
            "2050cbf8f38545f1bdcb74f5cac778c9"
          ]
        },
        "outputId": "7210d1d7-343d-4ae6-a148-1f7092b4a542"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/553M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4262e64b4484577b3e5d67fb2c6a101"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at flaubert/flaubert_base_cased were not used when initializing FlaubertModel: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n",
            "- This IS expected if you are initializing FlaubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing FlaubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "flaubert_model = AutoModel.from_pretrained(\"flaubert/flaubert_base_cased\", return_dict=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFQEpfkRexyy"
      },
      "outputs": [],
      "source": [
        "class WSDClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_labels, device, bert_model, bert_config, freeze_bert=True, layers_to_cat=1):\n",
        "        super(WSDClassifier, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        # instead of taking flaubert's embeddings only at the last layer\n",
        "        # we can use the concatenation of embeddings at the layers_to_cat last layers\n",
        "        self.layers_to_cat = layers_to_cat\n",
        "                \n",
        "        # the full *BERT*-like model\n",
        "        self.bert_layer = bert_model\n",
        "        # config will allow to get the hidden vectors' size\n",
        "        self.bert_config = bert_config\n",
        "        \n",
        "        # rest of the network (output linear layer and log softmax)\n",
        "        self.linear_layer = nn.Linear(bert_config.emb_dim * layers_to_cat, num_labels)\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "        # option to either freeze or fine-tune the BERT model\n",
        "        for param in self.bert_layer.parameters():\n",
        "          param.requires_grad = not freeze_bert\n",
        "\n",
        "        # the .to(device) triggers the copy towards the relevant device \n",
        "        # (possibly a GPU)\n",
        "        self.to(device)\n",
        "        \n",
        "\n",
        "    def forward(self, b_tid_seq, b_tg_trk):\n",
        "        \"\"\"\n",
        "        Inputs: (all are tensors, on the relevant device)\n",
        "            - a batch of sentences = a batch of token id sequences \n",
        "              (as output in 'input_ids' member of tokenizer output)\n",
        "            - a batch of target token rank = for each of the sentences, \n",
        "              the rank of first token of the target word to disambiguate\n",
        "\n",
        "        Output: log_softmax scores for the whole batch (batch_size x num_labels)\n",
        "        \"\"\"\n",
        "\n",
        "        #  list of *bert hidden vectors for all the tokens of all the batch sentences at all layers\n",
        "        all_layers = self.bert_layer(b_tid_seq, output_hidden_states=True).hidden_states\n",
        "        #  concatenation of the hidden vectors at the layers_to_cat last layers\n",
        "        #  [ batch_size x seq_len x (bert_emb_size * layers_to_cat) ]\n",
        "        all_token_representations = torch.cat(all_layers[-self.layers_to_cat:], dim=-1)\n",
        "\n",
        "        #  - isolate the vector of the (first) token of the target for all the batch sentences\n",
        "        #    [ batch_size x (bert_emb_size * layers_to_cat) ]\n",
        "        target_representations = all_token_representations[torch.arange(all_token_representations.size(0)), b_tg_trk]\n",
        "        #    Tips to do this:\n",
        "        #    https://discuss.pytorch.org/t/how-to-select-specific-vector-in-3d-tensor-beautifully/37724\n",
        "        \n",
        "        #  - and apply linear layer\n",
        "        #    [ batch_size x num_labels ]\n",
        "        scores = self.linear_layer(target_representations)\n",
        "        return self.log_softmax(scores)\n",
        "\n",
        "            \n",
        "    def run_on_dataset(self, wsd_data, batch_size=32):\n",
        "        \"\"\"\n",
        "        Run classifier on wsd_data and compute accuracy\n",
        "        Inputs = \n",
        "         - wsd_data (WSDDataset instance)\n",
        "         - batch_size\n",
        "        Returns:\n",
        "         - list of predicted label ids\n",
        "        \"\"\"\n",
        "        pred_labels = []\n",
        "        \n",
        "        # toggle evaluation mode of the model (VERY IMPORTANT)\n",
        "        self.eval()\n",
        "\n",
        "        with torch.no_grad(): # useless to compute gradients when evaluating\n",
        "          for b_tid_seqs, b_tg_trks, b_labels, b_tg_lemmas in wsd_data.make_batches(batch_size, self.device):\n",
        "            Y_hat = self(b_tid_seqs, b_tg_trks) # get all scores\n",
        "            pred_labels.extend(Y_hat.argmax(dim=-1).tolist()) # choose highest\n",
        "\n",
        "        return pred_labels\n",
        "\n",
        "\n",
        "    def evaluate(self, gold_labels, pred_labels):\n",
        "        \"\"\" returns accuracy, nb_correct, nb_total \"\"\"\n",
        "        gold_labels = torch.tensor(gold_labels)\n",
        "        pred_labels = torch.tensor(pred_labels)\n",
        "        nb_correct = (gold_labels == pred_labels).sum().item()\n",
        "        nb_total = gold_labels.shape[0]\n",
        "        accuracy = 100 * nb_correct / nb_total\n",
        "        return accuracy, nb_correct, nb_total\n",
        "\n",
        "    def load(self, filename):\n",
        "        \"\"\" loads parameters that were previously trained and saved \"\"\"\n",
        "        self.load_state_dict(torch.load(filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrkbQ4hVexy1"
      },
      "outputs": [],
      "source": [
        "# an instance of WSDClassifier\n",
        "num_labels = len(i2label)\n",
        "classifier = WSDClassifier(num_labels, DEVICE, flaubert_model, flaubert_config)\n",
        "\n",
        "# uncomment to see the huge nb of parameters ...\n",
        "#for name, param in classifier.named_parameters():\n",
        "#    print(\"PARAM named %s, of shape %s\" % (name, str(param.shape)))\n",
        "#    print(param)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LeXSxEXexy5"
      },
      "source": [
        "#### Test of forward propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4iIZvzDexy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "748d2ef4-2795-44f5-b7ae-91b738167cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GOLD LABEL of first ex 45 ( = Evidence)\n",
            "LOG_PROBS before training: tensor([-5.1482, -4.6172, -6.0138, -3.8711, -4.1902, -3.5959, -3.7637, -5.5234,\n",
            "        -5.8458, -5.2972, -4.5094, -5.6308, -5.5577, -5.1261, -5.5437, -4.2646,\n",
            "        -6.5333, -4.7462, -3.4424, -5.1902, -5.7456, -4.5710, -5.6263, -4.7519,\n",
            "        -4.8278, -5.0519, -5.5184, -5.6702, -4.5268, -5.3901, -4.2514, -5.0148,\n",
            "        -4.9086, -4.3648, -4.7188, -4.9056, -5.5119, -3.4815, -6.0087, -6.2005,\n",
            "        -4.7202, -4.4581, -5.2738, -4.7468, -4.8462, -5.5344, -4.6955, -4.7539,\n",
            "        -6.8399, -3.6715, -5.0130, -5.0550, -4.8980, -4.6851, -4.7190, -5.4565,\n",
            "        -5.0839, -4.2809, -5.2812, -3.5253, -4.4216, -5.4093, -4.4754, -3.8113,\n",
            "        -5.1358, -4.9758, -4.6529, -3.1754, -6.1799, -4.3250, -4.7841, -5.8441,\n",
            "        -4.0289, -4.5812, -5.5812, -3.2951, -5.4231, -5.8275, -4.9057, -4.7433,\n",
            "        -4.8012, -5.9500, -5.6076, -6.1345, -5.2078, -3.5000, -3.9181, -4.4877,\n",
            "        -4.6161, -6.9715, -5.8900, -4.1914, -5.2633, -4.2823, -5.1210, -5.2299,\n",
            "        -4.8708, -5.9895, -4.9415, -5.5999, -5.2500, -6.5562, -5.8734, -5.0987,\n",
            "        -4.4325, -5.4676, -4.0369], device='cuda:0')\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# useless to compute gradients when testing\n",
        "with torch.no_grad():\n",
        "    # toggle train mode off\n",
        "    classifier.eval()\n",
        "    for b_tid_seqs, b_tg_trks, b_labels, b_tg_lemmas in wsd_data['dev'].make_batches(32, classifier.device, shuffle_data=True):\n",
        "        b_tid_seqs = b_tid_seqs.to(classifier.device)\n",
        "        b_tg_trks = b_tg_trks.to(classifier.device)\n",
        "        \n",
        "        log_probs = classifier(b_tid_seqs, b_tg_trks)\n",
        "        gold = b_labels[0] #.item()\n",
        "        print(\"GOLD LABEL of first ex %d ( = %s)\" % (gold, i2label[gold]))\n",
        "        print(\"LOG_PROBS before training: %s\\n\\n\" % str(log_probs[0]))\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aikfNi0zexy9"
      },
      "source": [
        "### TODO6: Training : fine-tuning for the WSD task\n",
        "\n",
        "**NB** full training on train data is **LONG**, so when developping your code, first try on a small part of the data.\n",
        "\n",
        "**NB** In general when using a *bert model in fine-tuning mode (not frozen), the needed learning rate tends to be lower"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_epoch(classifier, train_data, batch_size, optimizer, loss_function):\n",
        "  \"\"\"\n",
        "  Trains classifier for one epoch\n",
        "  Inputs = \n",
        "    - classifier: model to train (WSDClassifier instance)\n",
        "    - train_data: wsd_data (WSDDataset instance)\n",
        "    - batch_size (int)\n",
        "    - optimizer: instance of Optimizer from torh.optim used to update the parameters\n",
        "    - loss_function: object with a call function that calculates the loss\n",
        "  Returns:\n",
        "    - average loss for this epoch (float)\n",
        "  \"\"\"\n",
        "\n",
        "  epoch_losses = []\n",
        "  classifier.train()\n",
        "  for b_tid_seqs, b_tg_trks, b_labels, b_tg_lemmas in train_data.make_batches(batch_size, classifier.device, shuffle_data=True):\n",
        "    \n",
        "    # Resets the gradient to zero before each forward propagation\n",
        "    classifier.zero_grad()\n",
        "    # Forward propagation\n",
        "    log_probs = classifier(b_tid_seqs, b_tg_trks)\n",
        "    loss = loss_function(log_probs, b_labels)\n",
        "    # Back propagation\n",
        "    loss.backward()\n",
        "    # Updates parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_losses.append(loss.item())\n",
        "\n",
        "  return sum(epoch_losses)/len(epoch_losses)\n",
        "\n",
        "\n",
        "def validation_epoch(classifier, val_data, batch_size, optimizer, loss_function):\n",
        "  \"\"\"\n",
        "  Runs classifier on a validation dataset and computes accuracy and average loss\n",
        "  Inputs = \n",
        "    - classifier: model to use (WSDClassifier instance)\n",
        "    - val_data: wsd_data (WSDDataset instance)\n",
        "    - batch_size (int)\n",
        "    - optimizer: instance of Optimizer from torh.optim used to update the parameters\n",
        "    - loss_function: object with a call function that calculates the loss\n",
        "  Returns:\n",
        "    - average loss on this dataset (float)\n",
        "    - accuracy on this dataset\n",
        "  \"\"\"\n",
        "\n",
        "  epoch_losses = []\n",
        "  classifier.eval()\n",
        "  with torch.no_grad():\n",
        "\n",
        "    pred_labels = []\n",
        "    for b_tid_seqs, b_tg_trks, b_labels, b_tg_lemmas in val_data.make_batches(BATCH_SIZE, DEVICE):\n",
        "      \n",
        "      log_probs = classifier(b_tid_seqs, b_tg_trks)\n",
        "\n",
        "      # compute loss\n",
        "      loss = loss_function(log_probs, b_labels)\n",
        "      epoch_losses.append(loss.item())\n",
        "\n",
        "      # to compute accuracy later\n",
        "      pred_labels.extend(log_probs.argmax(dim=-1).tolist())\n",
        "\n",
        "  epoch_loss = sum(epoch_losses)/len(epoch_losses)\n",
        "  accuracy, _, _ = classifier.evaluate(val_data.labels, pred_labels)\n",
        "  return epoch_loss, accuracy\n",
        "\n",
        "\n",
        "def train(classifier, train_data, val_data, lr, batch_size, epochs, patience, out_model_file):\n",
        "  \"\"\"\n",
        "  Trains and validates a classifier for a given number of epochs or until early stopping\n",
        "  Inputs = \n",
        "    - classifier: model to train (WSDClassifier instance)\n",
        "    - train_data: wsd_data (WSDDataset instance)\n",
        "    - val_data: wsd_data (WSDDataset instance)\n",
        "    - lr: learning rate (float)\n",
        "    - batch_size (int)\n",
        "    - epochs: maximum number of epochs to train for (int)\n",
        "    - patience: how long to wait before early stopping after the last time validation loss improved (int)\n",
        "    - out_model_file: path where to save the trained model\n",
        "  Returns:\n",
        "    - list of train losses for each epoch\n",
        "    - list of validation losses for each epoch\n",
        "  \"\"\"\n",
        "\n",
        "  loss_function = nn.NLLLoss(reduction='mean')\n",
        "  # SGD is quicker (more convenient for debug phase)\n",
        "  #optimizer = optim.SGD(classifier.parameters(), lr=lr)\n",
        "  optimizer = optim.Adam(classifier.parameters(), lr=lr)\n",
        "\n",
        "  # losses at each epoch (on train / on validation set)\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  val_accuracies = []\n",
        "  min_val_loss = None # used to find the best iteration\n",
        "\n",
        "  for e in range(epochs):\n",
        "    print(f\"EPOCH {e}\")\n",
        "    \n",
        "    # train\n",
        "    train_loss = training_epoch(classifier, train_data, batch_size, optimizer, loss_function)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # validate\n",
        "    val_loss, accuracy = validation_epoch(classifier, val_data, batch_size, optimizer, loss_function)    \n",
        "    val_losses.append(val_loss)    \n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"train loss: {train_loss}, validation loss: {val_loss}, validation accuracy: {accuracy}\\n\")\n",
        "\n",
        "    # early stopping\n",
        "    if min_val_loss == None or val_loss < min_val_loss:\n",
        "      min_val_loss = val_loss  \n",
        "      counter = 0\n",
        "      # save the model  (it's the best one so far)\n",
        "      torch.save(classifier.state_dict(), out_model_file)\n",
        "    else:\n",
        "      counter += 1\n",
        "      if counter >= patience:\n",
        "          print(f\"EARLY STOP - best epoch was epoch {e-counter}\")\n",
        "          break\n",
        "  \n",
        "  return train_losses, val_losses"
      ],
      "metadata": {
        "id": "2xfj7wf01GmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOKrCRPFexy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d704b968-b8bb-4f93-a64e-f0f139fb3a8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 0\n",
            "train loss: 1.4555628785531816, validation loss: 0.4583070561999366, validation accuracy: 85.86309523809524\n",
            "\n",
            "EPOCH 1\n",
            "train loss: 0.407011967815765, validation loss: 0.3549931957608178, validation accuracy: 88.69047619047619\n",
            "\n",
            "EPOCH 2\n",
            "train loss: 0.24337722958154875, validation loss: 0.3238854848203205, validation accuracy: 89.73214285714286\n",
            "\n",
            "EPOCH 3\n",
            "train loss: 0.14291889391431253, validation loss: 0.3328513708852586, validation accuracy: 90.06696428571429\n",
            "\n",
            "EPOCH 4\n",
            "train loss: 0.12325168847527405, validation loss: 0.3644834253050032, validation accuracy: 90.10416666666667\n",
            "\n",
            "EPOCH 5\n",
            "train loss: 0.08175288395292751, validation loss: 0.39830060374169124, validation accuracy: 90.47619047619048\n",
            "\n",
            "EPOCH 6\n",
            "train loss: 0.05434332166683592, validation loss: 0.377723766934304, validation accuracy: 90.69940476190476\n",
            "\n",
            "EPOCH 7\n",
            "train loss: 0.03794409042823907, validation loss: 0.3876177817583084, validation accuracy: 90.8110119047619\n",
            "\n",
            "EARLY STOP - best epoch was epoch 2\n",
            "train losses: 1.4556 / 0.4070 / 0.2434 / 0.1429 / 0.1233 / 0.0818 / 0.0543 / 0.0379\n",
            "val   losses: 0.4583 / 0.3550 / 0.3239 / 0.3329 / 0.3645 / 0.3983 / 0.3777 / 0.3876\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "\n",
        "# an instance of WSDClassifier\n",
        "num_labels = len(i2label)\n",
        "classifier = WSDClassifier(num_labels, DEVICE, flaubert_model, flaubert_config, freeze_bert=False)#, layers_to_cat=4)\n",
        "\n",
        "# hyperparameters\n",
        "BATCH_SIZE = 128\n",
        "LR = 0.00005\n",
        "NB_EPOCHS = 20\n",
        "PATIENCE = 5\n",
        "\n",
        "config_name = 'sequoiaftb.asfalda_1_3.wsd.lr' + 'Adam' + str(LR) + '_bs' + str(BATCH_SIZE)\n",
        "out_model_file = './' + config_name + '.model'\n",
        "out_log_file = './' + config_name + '.log'\n",
        "\n",
        "# to speed up during debug: train on dev\n",
        "test_data = wsd_data['test']\n",
        "train_data = wsd_data['train']\n",
        "val_data = wsd_data['dev']\n",
        "\n",
        "# training\n",
        "# - basic : train for NB_EPOCHS\n",
        "# - BONUS : early stopping: stop epoch loop as soon as accuracy on dev decreases\n",
        "train_losses, val_losses = train(classifier, train_data, val_data, LR, BATCH_SIZE, NB_EPOCHS, PATIENCE, out_model_file)\n",
        "\n",
        "print(\"train losses: %s\" % ' / '.join([ \"%.4f\" % x for x in train_losses]))\n",
        "print(\"val   losses: %s\" % ' / '.join([ \"%.4f\" % x for x in val_losses]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F59TuDyAWMw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "2be2738a-4ded-40d6-eaf2-c0b070bb3e4c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Graphs to visualize the training process\n",
        "\n",
        "from matplotlib import pyplot as plt \n",
        "\n",
        "plt.plot(train_losses, label = 'loss on training')\n",
        "plt.plot(val_losses, label = 'loss on validation')\n",
        "plt.title('Learning curve')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('NLL loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHt6rTougG0K"
      },
      "source": [
        "### TODO7: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.load(out_model_file)"
      ],
      "metadata": {
        "id": "wEu5AzQNr_zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHYxcJBNexzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cee5659-bcb6-4bf6-c9ae-9eccdf0a426d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 90.94865100087033\n",
            "Number of correct examples: 3135\n",
            "Total number of examples: 3447\n"
          ]
        }
      ],
      "source": [
        "# run on dev and evaluate (I'm running on test)\n",
        "\n",
        "pred_labels = classifier.run_on_dataset(test_data, batch_size=BATCH_SIZE)\n",
        "accuracy, nb_correct, nb_total = classifier.evaluate(test_data.labels, pred_labels)\n",
        "\n",
        "print(f'Accuracy: {accuracy}\\nNumber of correct examples: {nb_correct}\\nTotal number of examples: {nb_total}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generalization analysis"
      ],
      "metadata": {
        "id": "3emelQCOSExz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1owCYuPRiCKx"
      },
      "outputs": [],
      "source": [
        "# toggle evaluation mode of the model\n",
        "classifier.eval()\n",
        "\n",
        "gold_unseen = 0 # number of gold lemma-frame associations unseen in train\n",
        "pred_unseen = 0 # number of predicted lemma-frame associations unseen in train\n",
        "wrong_pred_unseen = 0 # number of predicted unseen in train lemma-frame associations that are wrong\n",
        "correct_pred_unseen = 0 # number of predicted unseen in train lemma-frame associations that are correct\n",
        "wrong = 0 # number of wrong predictions\n",
        "\n",
        "with torch.no_grad(): \n",
        "  for b_tid_seqs, b_tg_trks, b_labels, b_tg_lemmas in test_data.make_batches(BATCH_SIZE, DEVICE):\n",
        "    \n",
        "    Y_hat = classifier(b_tid_seqs, b_tg_trks) \n",
        "    pred_labels = Y_hat.argmax(dim=-1) \n",
        "\n",
        "    for b in range(len(b_labels)):\n",
        "      # if the gold lemma-frame association for this example is not in the train associations\n",
        "      gold_unseen_association = (b_tg_lemmas[b] + i2label[b_labels[b]]) not in train_associations\n",
        "      # if the predicted lemma-frame association for this example is not in the train associations\n",
        "      pred_unseen_association = (b_tg_lemmas[b] + i2label[pred_labels[b]]) not in train_associations\n",
        "      # if the prediction is wrong\n",
        "      wrong_prediction = b_labels[b] != pred_labels[b]\n",
        "\n",
        "      gold_unseen += gold_unseen_association\n",
        "      pred_unseen += pred_unseen_association\n",
        "      wrong_pred_unseen += (wrong_prediction and pred_unseen_association)\n",
        "      correct_pred_unseen += (not wrong_prediction and pred_unseen_association)\n",
        "      wrong += wrong_prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of gold lemma-frame associations unseen in training: {gold_unseen}\")\n",
        "print(f\"Number of predicted lemma-frame associations unseen in training: {pred_unseen}\\n\")\n",
        "\n",
        "print(f\"Number of predicted lemma-frame associations unseen in training that were wrong: {wrong_pred_unseen}\")\n",
        "print(f\"Number of predicted lemma-frame associations unseen in training that were correct: {correct_pred_unseen}\\n\")\n",
        "\n",
        "print(f\"Percentage of unseen in training lemma-frame associations predicted that were correct: {(correct_pred_unseen/pred_unseen) * 100}\")\n",
        "print(f\"Percentage of unseen in training lemma-frame associations predicted that were wrong: {(wrong_pred_unseen/pred_unseen) * 100}\\n\")\n",
        "\n",
        "print(f\"Number of wrong predictions {wrong}\")\n",
        "print(f\"Percentage of wrong predictions that were lemma-frame associations unseen in training: {(wrong_pred_unseen/wrong) * 100}\\n\")\n",
        "\n",
        "print(f\"Percentage of gold target-lemma associations that are unseen in training: {(gold_unseen/len(test_data.tg_lemmas)) * 100}\\n\")\n",
        "\n",
        "print(f\"Percentage of predicted target-lemma associations that are wrong and unseen in training: {(wrong_pred_unseen/len(test_data.tg_lemmas)) * 100}\")\n",
        "print(f\"Percentage of predicted target-lemma associations that are correct and unseen in training: {100*correct_pred_unseen/len(test_data.tg_lemmas)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_2S66Prdf_V",
        "outputId": "0c5fbc0d-ea3e-4b87-911c-5383e57ba13b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of gold lemma-frame associations unseen in training: 61\n",
            "Number of predicted lemma-frame associations unseen in training: 80\n",
            "\n",
            "Number of predicted lemma-frame associations unseen in training that were wrong: 54\n",
            "Number of predicted lemma-frame associations unseen in training that were correct: 26\n",
            "\n",
            "Percentage of unseen in training lemma-frame associations predicted that were correct: 32.5\n",
            "Percentage of unseen in training lemma-frame associations predicted that were wrong: 67.5\n",
            "\n",
            "Number of wrong predictions 359\n",
            "Percentage of wrong predictions that were lemma-frame associations unseen in training: 15.041783332824707\n",
            "\n",
            "Percentage of gold target-lemma associations that are unseen in training: 1.769654772265738\n",
            "\n",
            "Percentage of predicted target-lemma associations that are wrong and unseen in training: 1.5665795803070068\n",
            "Percentage of predicted target-lemma associations that are correct and unseen in training: 0.7542790832608065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6CDdnT5qXHQ"
      },
      "source": [
        "## Scale (\"barème\")\n",
        "\n",
        "- basic system will give 12 points\n",
        "\n",
        "- quality of code / comments = 2 points\n",
        "\n",
        "\n",
        "- various additional points (to choose)\n",
        "\n",
        "  - generalization analysis\n",
        "   Do you think it would be better to predict seen-in-train lemma/frame associations only ?\n",
        "   (in order to answer that question, propose and implement simple analysis of the predictions performed without any control of the frame/lemma association)\n",
        "\n",
        "  - implement an option to only predict seen-in-train lemma/frame associations\n",
        "\n",
        "  - nice hyperparameter search\n",
        "\n",
        "  - high results thanks to nice hyperparameter search\n",
        "\n",
        "  - implement early stopping\n",
        "\n",
        "  - does it help to fine-tune with a MLP instead of single layer ?\n",
        "\n",
        "  - does it help to use a concatenation of flaubert's embeddings at different layers instead of the last layer only (eg 4 last layers, cf. table 7 of devlin et al. 2019) (do this in frozen mode only)\n",
        "\n",
        "  - does it help to add a lemma embedding of the target (concatenate it to the bert output, before final linear layer)?\n",
        "\n",
        "  - ... other ideas are welcome ...\n",
        "\n",
        "Approximate expected accuracy:\n",
        " - In frozen mode, basic system can reach 83 / 84 % on the dev set when well trained\n",
        "\n",
        " - In fine-tuning mode: results seem unstable\n",
        "  - take care to search for an appropriate learning rate\n",
        "  - some of the runs get stuck at 37% of accuracy, corresponding to assigning the MFS to all the instances (\"other_sense\" frame)\n",
        "  - when learning goes well, accuracy can reach 88, or even 90% for some runs\n",
        "\n",
        "\n",
        "NB: write below what you chose to investigate / implement.\n",
        "Summarize your results / hyper-parameter search.\n",
        "\n",
        "Your notebook should show traces of a complete training and evaluation phase."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional points implemented\n",
        "\n",
        "- ### Early stopping\n",
        "\n",
        "  Early stopping is implemented in the `train` function. When validation loss hasn't improved for `patience` epochs, training is interrupted. The model which is saved is the one that achieved the best validation loss, not the one at the end of the training procedure.\n",
        "\n",
        "  When training the model, I noticed that sometimes loss started to become worse while accuracy on the dev set was still improving a little. Using the parameters that obtained the best validation loss, I had a better accuracy on the test set than using those that obtained the best validation accuracy. So, I used loss as a stopping criterion for early stopping instead of using accuracy as was suggested. \n",
        "\n",
        "- ### Concatenation of flaubert's embeddings at different layers\n",
        "  \n",
        "  As suggested by the results in table 7 of devlin et al. 2019, I implemented an option to use as contextual representations not only the embeddings produced at the last flaubert layer, but a concatenation of those produced by different layers. The model now uses a concatenation of the embeddings at the last `layers_to_cat` layers instead of only the last one.\n",
        "\n",
        "  With flaubert's parameter's frozen, by using the concatenation of the 4 last layer embeddings, as suggested in the paper, the test accuracy increased from 86.02% to 87.32%.\n",
        "\n",
        "  I tried to use the concatenation with fine-tuning (parameters not frozen), but this did not lead to a better performance. Accuracy stayed roughly the same and even decreased sometimes.\n",
        "\n",
        "- ### Best hyperparameters\n",
        "\n",
        "  The best set of hyperparameters I have found (through trial and error, no 'nice' hyperparameter search, sorry...) in fine-tuning mode is a learning rate of 0.00005, a batch size of 128 and no concatenation of layer embeddings. This model achieved an accuracy of 90.95% on the test set.\n",
        "\n",
        "  In feature extraction mode (with flaubert parameters frozen), the best combination was a learning rate of 0.0005, a batch size of 256 and the concatenation of the embeddings at the four last layers. This model achieved an accuracy of 87.32% on the test set. \n",
        "\n",
        "- ### Generalization analysis\n",
        "\n",
        "  In the last code block, I ran some tests to assess whether it could be better to predict seen-in-train lemma/frame associations only. I measured that 15% of the wrong predictions the model made were unseen target-lemma associations. These make up 1.57% of all predictions. So, it looks like we could gain +1.57 accuracy by blocking unseen in training associations from being predicted.\n",
        "  \n",
        "  However, there are also unseen associations in the gold data. 26 of those were correctly predicted by the current model (or 0.75% of test examples). So, in reality, the proposed modification could only produce a gain in accuracy of up to 1.57 - 0.75 = +0.82. Given that we are not even sure the model's second-best prediction that we would use instead would be the correct one, the improvement would probably be less than that.\n",
        "  \n",
        "  The modification would also make it plain impossible for the model to correctly predict all unseen associations in the gold data (1.77% of the test data), even if we managed to improve the model in other ways. So, I am not fully convinced by the idea of blocking unseen in training target-lemma associations. But the only way to know for sure would be to try it, which I didn't have time to do, maybe the small gain would make it worthwhile after all.\n",
        "\n",
        "  @@ C'est un excellent TP, bravo. Analyse très pertinente."
      ],
      "metadata": {
        "id": "1UVN0HjagR6C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IwJCUGHXKlLQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5e7465a736804aa09fd27f8757a6f479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1187eac5919c4ed6bc71e8cf188d48e5",
              "IPY_MODEL_898340f77607446abe6df27e33490c72",
              "IPY_MODEL_3e80a4a990de4bbdb72d7c240f056bd1"
            ],
            "layout": "IPY_MODEL_415b0d74ac1a43b1b078319813975505"
          }
        },
        "1187eac5919c4ed6bc71e8cf188d48e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccaf0691ccb94516b383693177222cde",
            "placeholder": "​",
            "style": "IPY_MODEL_7f455f64075749369398772db9115446",
            "value": "Downloading: 100%"
          }
        },
        "898340f77607446abe6df27e33490c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6204413c55884a65aeb0be525a8c3ff9",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cacbeb290ca4afa84d56e9dcd52d329",
            "value": 28
          }
        },
        "3e80a4a990de4bbdb72d7c240f056bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8cf651b69e54d2fb898f2e4836affae",
            "placeholder": "​",
            "style": "IPY_MODEL_7a85ac5a5d8b48e3846b9c2d872276a6",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.12kB/s]"
          }
        },
        "415b0d74ac1a43b1b078319813975505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccaf0691ccb94516b383693177222cde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f455f64075749369398772db9115446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6204413c55884a65aeb0be525a8c3ff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cacbeb290ca4afa84d56e9dcd52d329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8cf651b69e54d2fb898f2e4836affae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a85ac5a5d8b48e3846b9c2d872276a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcbf1eb91e1a41a18d56a6aa2e9f2ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8b97bc5d55e45b7994dfdc0e8930f40",
              "IPY_MODEL_cc685603f54b44b586bd66cecfe1bbd4",
              "IPY_MODEL_6d34d1adc92f4216a604ac2055565231"
            ],
            "layout": "IPY_MODEL_8f2f6524e96a447b9c935f8efd14787d"
          }
        },
        "a8b97bc5d55e45b7994dfdc0e8930f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c83e8ffcde04a18ae9b7c482c199664",
            "placeholder": "​",
            "style": "IPY_MODEL_83ddeba84ec34445ba3c6ba6be426f93",
            "value": "Downloading: 100%"
          }
        },
        "cc685603f54b44b586bd66cecfe1bbd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b98f099d8884134889de26a2cb7b75e",
            "max": 1496,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6684c23529184193aa737636621e1037",
            "value": 1496
          }
        },
        "6d34d1adc92f4216a604ac2055565231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f47514275b744841b4db1300af057a35",
            "placeholder": "​",
            "style": "IPY_MODEL_b12afaafc9e54c699c9c755af10e0d0e",
            "value": " 1.50k/1.50k [00:00&lt;00:00, 69.7kB/s]"
          }
        },
        "8f2f6524e96a447b9c935f8efd14787d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c83e8ffcde04a18ae9b7c482c199664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ddeba84ec34445ba3c6ba6be426f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b98f099d8884134889de26a2cb7b75e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6684c23529184193aa737636621e1037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f47514275b744841b4db1300af057a35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b12afaafc9e54c699c9c755af10e0d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f235ac96cf38423da305c6171db88c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c25691722bb6401f9917887fe54fa198",
              "IPY_MODEL_57abc02fb02045a1820a6824209d6184",
              "IPY_MODEL_fa8e5c31de3849cfaac0807921fbb27f"
            ],
            "layout": "IPY_MODEL_9c10991d921f42608e8320ef89440b63"
          }
        },
        "c25691722bb6401f9917887fe54fa198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3cdefbf686e4ca1a031280ed4135a24",
            "placeholder": "​",
            "style": "IPY_MODEL_738857fe0b404704b217013138604933",
            "value": "Downloading: 100%"
          }
        },
        "57abc02fb02045a1820a6824209d6184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_449d706b28a743e6b3daa82c5aa8744e",
            "max": 1561415,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4750320a4c244a9b3667563d40e45aa",
            "value": 1561415
          }
        },
        "fa8e5c31de3849cfaac0807921fbb27f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f967f713f7f4471489205c74ea370f5a",
            "placeholder": "​",
            "style": "IPY_MODEL_37a904a758014211a2a6962ea0f8edf8",
            "value": " 1.56M/1.56M [00:00&lt;00:00, 4.68MB/s]"
          }
        },
        "9c10991d921f42608e8320ef89440b63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3cdefbf686e4ca1a031280ed4135a24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738857fe0b404704b217013138604933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "449d706b28a743e6b3daa82c5aa8744e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4750320a4c244a9b3667563d40e45aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f967f713f7f4471489205c74ea370f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37a904a758014211a2a6962ea0f8edf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83afd2924f8c48a794d072864615a432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c7497af351f4f14989dabc38da34d5c",
              "IPY_MODEL_df6f571ef05b4581a54a45ef0fa3e2c2",
              "IPY_MODEL_f39313e28cf74e898dbeb575a691f01a"
            ],
            "layout": "IPY_MODEL_752e47be8999489094eb11e8c704a87b"
          }
        },
        "5c7497af351f4f14989dabc38da34d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4491356ec2b49bd8748ce8d7713e337",
            "placeholder": "​",
            "style": "IPY_MODEL_8088ba76a156495fb2506fa06ea6b087",
            "value": "Downloading: 100%"
          }
        },
        "df6f571ef05b4581a54a45ef0fa3e2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8301e35efd58444d9e8d82f8412713b2",
            "max": 895731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88d1bbbd69214de5b359c035fdf603b4",
            "value": 895731
          }
        },
        "f39313e28cf74e898dbeb575a691f01a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ed363b6d28948919a89fcc2eb6cde22",
            "placeholder": "​",
            "style": "IPY_MODEL_6b40ca9e0c994101a1d04e91cacee63c",
            "value": " 896k/896k [00:00&lt;00:00, 2.00MB/s]"
          }
        },
        "752e47be8999489094eb11e8c704a87b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4491356ec2b49bd8748ce8d7713e337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8088ba76a156495fb2506fa06ea6b087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8301e35efd58444d9e8d82f8412713b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d1bbbd69214de5b359c035fdf603b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ed363b6d28948919a89fcc2eb6cde22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b40ca9e0c994101a1d04e91cacee63c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4262e64b4484577b3e5d67fb2c6a101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1720abdea6f742d990958da02b3a2c9e",
              "IPY_MODEL_316fc044b78d40b3b7a77f74525d2495",
              "IPY_MODEL_a94e6bb12dec4ce8a67260a8f43268c6"
            ],
            "layout": "IPY_MODEL_8d00811bf2d043d0ab5dee18601982e2"
          }
        },
        "1720abdea6f742d990958da02b3a2c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe70c3ad2dcc4dec8af9b239b67ea0bb",
            "placeholder": "​",
            "style": "IPY_MODEL_f782810f814747679e7817eb8d0662b8",
            "value": "Downloading: 100%"
          }
        },
        "316fc044b78d40b3b7a77f74525d2495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_253b4b474f6047fea2d60c902cb9c937",
            "max": 553238687,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06f8a9fc99714cf2b3fb644860b4ad8f",
            "value": 553238687
          }
        },
        "a94e6bb12dec4ce8a67260a8f43268c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ccdac42fac046518c29c0a2ce7dfd57",
            "placeholder": "​",
            "style": "IPY_MODEL_2050cbf8f38545f1bdcb74f5cac778c9",
            "value": " 553M/553M [00:13&lt;00:00, 44.0MB/s]"
          }
        },
        "8d00811bf2d043d0ab5dee18601982e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe70c3ad2dcc4dec8af9b239b67ea0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f782810f814747679e7817eb8d0662b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "253b4b474f6047fea2d60c902cb9c937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06f8a9fc99714cf2b3fb644860b4ad8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ccdac42fac046518c29c0a2ce7dfd57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2050cbf8f38545f1bdcb74f5cac778c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}